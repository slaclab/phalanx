jupyterhub:
  debug:
    enabled: true
  hub:
    resources:
      requests:
        cpu: "1"
        memory: 3Gi
  ingress:
    hosts: ["rubin-data-dev.slac.stanford.edu"]
    annotations:
      nginx.ingress.kubernetes.io/auth-signin: "https://rubin-data-dev.slac.stanford.edu/login"
      nginx.ingress.kubernetes.io/auth-url: "https://rubin-data-dev.slac.stanford.edu/auth?scope=exec:notebook&notebook=true"

config:
  base_url: "https://rubin-data-dev.slac.stanford.edu"
  butler_secret_path: "secret/rubin/usdf-staffrsp-dev/butler-secret"
  pull_secret_path: "secret/rubin/usdf-staffrsp-dev/pull-secret"

<<<<<<< HEAD
    lab_environment:
      PGPASSFILE: "/opt/lsst/software/jupyterlab/butler-secret/postgres-credentials.txt"
      AWS_SHARED_CREDENTIALS_FILE: "/opt/lsst/software/jupyterlab/butler-secret/aws-credentials.ini"
      S3_ENDPOINT_URL: "https://storage.googleapis.com"
      AUTO_REPO_URLS: https://github.com/lsst-sqre/system-test,https://github.com/rubin-dp0/tutorial-notebooks
      AUTO_REPO_BRANCH: prod
      AUTO_REPO_SPECS: https://github.com/lsst-sqre/system-test@prod,https://github.com/rubin-dp0/tutorial-notebooks@prod

    volumes:
      - name: datasets
        hostPath:
          path: /data
      - name: home
        hostPath:
          path: /tmp
      - name: project
        hostPath:
          path: /tmp 
      - name: scratch
        hostPath:
          path: /tmp
    volume_mounts:
      - name: datasets
        mountPath: /datasets
      - name: home
        mountPath: /home
      - name: project
        mountPath: /project
      - name: scratch
        mountPath: /scratch
=======
  lab_environment:
    PGPASSFILE: "/opt/lsst/software/jupyterlab/butler-secret/postgres-credentials.txt"
    AWS_SHARED_CREDENTIALS_FILE: "/opt/lsst/software/jupyterlab/butler-secret/aws-credentials.ini"
    S3_ENDPOINT_URL: "https://storage.googleapis.com"
    AUTO_REPO_URLS: ""   #https://github.com/lsst-sqre/system-test,https://github.com/rubin-dp0/tutorial-notebooks
    AUTO_REPO_BRANCH: "" #prod
    AUTO_REPO_SPECS: ""  #https://github.com/lsst-sqre/system-test@prod,https://github.com/rubin-dp0/tutorial-notebooks@prod
    http_proxy: http://squid.slac.stanford.edu:3128
    https_proxy: http://squid.slac.stanford.edu:3128
    no_proxy: hub.nublado2,.slac.stanford.edu
  volumes:
    - name: datasets
      persistentVolumeClaim:
        claimName: sdf-group-rubin-datasets
    - name: home
      persistentVolumeClaim:
        claimName: sdf-home
    - name: project
      persistentVolumeClaim:
        claimName: sdf-group-rubin
    - name: scratch
      persistentVolumeClaim:
        claimName: sdf-group-rubin-scratch
  volume_mounts:
    - name: datasets
      mountPath: /datasets
    - name: home
      #mountPath: "/home/{{user}}"
      mountPath: /home/
      #subPath: "{{user[0]}}/{{user}}"
    - name: project
      mountPath: /project
    - name: scratch
      mountPath: /scratch
>>>>>>> c46dc451 (fix: remove indents)

  # Workaround to impose resource quotas at IDF
  user_resources_template: |
    - apiVersion: v1
      kind: Namespace
      metadata:
        name: "{{ user_namespace }}"
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: group
        namespace: "{{ user_namespace }}"
      data:
        group: |
          root:x:0:
          bin:x:1:
          daemon:x:2:
          sys:x:3:
          adm:x:4:
          tty:x:5:
          disk:x:6:
          lp:x:7:
          mem:x:8:
          kmem:x:9:
          wheel:x:10:
          cdrom:x:11:
          mail:x:12:
          man:x:15:
          dialout:x:18:
          floppy:x:19:
          games:x:20:
          tape:x:33:
          video:x:39:
          ftp:x:50:
          lock:x:54:
          audio:x:63:
          nobody:x:99:
          users:x:100:
          utmp:x:22:
          utempter:x:35:
          input:x:999:
          systemd-journal:x:190:
          systemd-network:x:192:
          dbus:x:81:
          ssh_keys:x:998:
          tss:x:59:
          cgred:x:997:
          screen:x:84:
          provisionator:x:769:
          {{user}}:x:{{uid}}:{% for group in groups %}
          {{ group.name }}:x:{{ group.id }}:{{ user }}{% endfor %}
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: gshadow
        namespace: "{{ user_namespace }}"
      data:
        gshadow: |
          root:!::
          bin:!::
          daemon:!::
          sys:!::
          adm:!::
          tty:!::
          disk:!::
          lp:!::
          mem:!::
          kmem:!::
          wheel:!::
          cdrom:!::
          mail:!::
          man:!::
          dialout:!::
          floppy:!::
          games:!::
          tape:!::
          video:!::
          ftp:!::
          lock:!::
          audio:!::
          nobody:!::
          users:!::
          utmp:!::
          utempter:!::
          input:!::
          systemd-journal:!::
          systemd-network:!::
          dbus:!::
          ssh_keys:!::
          tss:!::
          cgred:!::
          screen:!::
          provisionator:!::
          {{ user }}:!::{% for g in groups %}
          {{ g.name }}:!::{{ user }}{% endfor %}
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: passwd
        namespace: "{{ user_namespace }}"
      data:
        passwd: |
          root:x:0:0:root:/root:/bin/bash
          bin:x:1:1:bin:/bin:/sbin/nologin
          daemon:x:2:2:daemon:/sbin:/sbin/nologin
          adm:x:3:4:adm:/var/adm:/sbin/nologin
          lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
          sync:x:5:0:sync:/sbin:/bin/sync
          shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
          halt:x:7:0:halt:/sbin:/sbin/halt
          mail:x:8:12:mail:/var/spool/mail:/sbin/nologin
          operator:x:11:0:operator:/root:/sbin/nologin
          games:x:12:100:games:/usr/games:/sbin/nologin
          ftp:x:14:50:FTP User:/var/ftp:/sbin/nologin
          nobody:x:99:99:Nobody:/:/sbin/nologin
          systemd-network:x:192:192:systemd Network Management:/:/sbin/nologin
          dbus:x:81:81:System message bus:/:/sbin/nologin
          tss:x:59:59:Account used by the trousers package to sandbox the tcsd daemon:/dev/null:/sbin/nologin
          provisionator:x:769:769:Lab provisioning user:/home/provisionator:/bin/bash
          {{ user }}:x:{{ uid }}:{{ uid }}::/home/{{ user[0] }}/{{ user }}:/bin/bash
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: shadow
        namespace: "{{ user_namespace }}"
      data:
        shadow: |
          root:*:18000:0:99999:7:::
          bin:*:18000:0:99999:7:::
          daemon:*:18000:0:99999:7:::
          adm:*:18000:0:99999:7:::
          lp:*:18000:0:99999:7:::
          sync:*:18000:0:99999:7:::
          shutdown:*:18000:0:99999:7:::
          halt:*:18000:0:99999:7:::
          mail:*:18000:0:99999:7:::
          operator:*:18000:0:99999:7:::
          games:*:18000:0:99999:7:::
          ftp:*:18000:0:99999:7:::
          nobody:*:18000:0:99999:7:::
          systemd-network:*:18000:0:99999:7:::
          dbus:*:18000:0:99999:7:::
          lsst_lcl:*:18000:0:99999:7:::
          tss:*:18000:0:99999:7:::
          provisionator:*:18000:0:99999:7:::
          {{user}}:*:18000:0:99999:7:::

    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: dask
        namespace: "{{ user_namespace }}"
      data:
        dask_worker.yml: |
          {{ dask_yaml | indent(6) }}
    # When we break out the resources we should make this per-instance
    #  configurable.
    - apiVersion: v1
      kind: ConfigMap
      metadata:
        name: idds-config
        namespace: "{{ user_namespace }}"
      data:
        idds_cfg.client.template: |
          # Licensed under the Apache License, Version 2.0 (the "License");
          # You may not use this file except in compliance with the License.
          # You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0
          #
          # Authors:
          # - Wen Guan, <wen.guan@cern.ch>, 2020
          [common]
          # if logdir is configured, idds will write to idds.log in this directory.
          # else idds will go to stdout/stderr.
          # With supervisord, it's good to write to stdout/stderr, then supervisord can manage and rotate logs.
          # logdir = /var/log/idds
          loglevel = INFO
          [rest]
          host = https://iddsserver.cern.ch:443/idds
          #url_prefix = /idds
          #cacher_dir = /tmp
          cacher_dir = /data/idds
    - apiVersion: v1
      kind: ServiceAccount
      metadata:
        name: "{{ user }}-serviceaccount"
        namespace: "{{ user_namespace }}"
      imagePullSecrets:
      - name: pull-secret
    - apiVersion: rbac.authorization.k8s.io/v1
      kind: Role
      metadata:
        name: "{{ user }}-role"
        namespace: "{{ user_namespace }}"
      rules:
      # cf https://kubernetes.dask.org/en/latest/kubecluster.html
        - apiGroups: [""]
          resources: ["pods", "services"]
          verbs: ["create", "delete", "get", "list", "watch"]
        - apiGroups: [""]
          resources: ["pods/log"]
          verbs: ["get","list"]
        - apiGroups: ["policy"]
          resources: ["poddisruptionbudgets"]
          verbs: ["create", "delete", "get", "list", "watch"]
    - apiVersion: rbac.authorization.k8s.io/v1
      kind: RoleBinding
      metadata:
        name: "{{ user }}-rolebinding"
        namespace: "{{ user_namespace }}"
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: Role
        name: "{{ user }}-role"
      subjects:
        - kind: ServiceAccount
          name: "{{ user }}-serviceaccount"
          namespace: "{{ user_namespace }}"
    - apiVersion: ricoberger.de/v1alpha1
      kind: VaultSecret
      metadata:
        name: butler-secret
        namespace: "{{ user_namespace }}"
      spec:
        path: "{{ butler_secret_path }}"
        type: Opaque
    - apiVersion: ricoberger.de/v1alpha1
      kind: VaultSecret
      metadata:
        name: pull-secret
        namespace: "{{ user_namespace }}"
      spec:
        path: "{{ pull_secret_path }}"
        type: kubernetes.io/dockerconfigjson
    - apiVersion: v1
      kind: ResourceQuota
      metadata:
        name: user-quota
        namespace: "{{ user_namespace }}"
      spec:
        hard:
          limits.cpu: 9
          limits.memory: 27Gi
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: sdf-group-rubin-scratch
        namespace: "{{ user_namespace }}"
      spec:
        storageClassName: sdf-group-rubin-scratch
        accessModes:
          - ReadWriteMany
        resources:
          requests:
            storage: 1Gi
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: sdf-group-rubin-datasets
        namespace: "{{ user_namespace }}"
      spec:
        storageClassName: sdf-group-rubin-datasets
        accessModes:
          - ReadWriteMany
        resources:
          requests:
            storage: 1Gi
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: sdf-group-rubin
        namespace: "{{ user_namespace }}"
      spec:
        storageClassName: sdf-group-rubin
        accessModes:
          - ReadWriteMany
        resources:
          requests:
            storage: 1Gi
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: sdf-home
        namespace: "{{ user_namespace }}"
      spec:
        storageClassName: sdf-home
        accessModes:
          - ReadWriteMany
        resources:
          requests:
            storage: 1Gi

vault_secret_path: "secret/rubin/usdf-staffrsp-dev/nublado2"

pull-secret:
  enabled: true
  path: "secret/rubin/usdf-staffrsp-dev/pull-secret"
